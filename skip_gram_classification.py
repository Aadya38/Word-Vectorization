# -*- coding: utf-8 -*-
"""skip-gram-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lEzXhha5V-7TbKAiSlBu-2KtfnREAd7p
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import pandas as pd
import numpy as np
import string
from collections import Counter
from tqdm import tqdm
import torch.nn.utils.rnn as rnn_utils


# Define the LSTM-based text classifier
class LSTMTextClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(LSTMTextClassifier, self).__init__()
        self.hidden_size = hidden_size
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        # Forward pass through the LSTM layer
        _, (h_n, _) = self.lstm(x)
        # Get the output and apply the fully connected layer
        output = self.fc(h_n[-1])
        return output


# Define a custom dataset class for text data
class CustomTextDataset(Dataset):
    def __init__(self, data, word_vectors, vocab, max_len):
        self.data = data
        self.word_vectors = word_vectors
        self.vocab = vocab
        self.max_len = max_len

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # Retrieve text and label from the dataset
        text = self.data.iloc[idx]['Text']
        label = self.data.iloc[idx]['Label'] - 1
        # Tokenize the text and convert it to a tensor
        tokenized_text = self.preprocess_text(text)
        text_vector = self.get_sentence_vector(tokenized_text)
        return text_vector, label

    def preprocess_text(self, text):
        # Preprocess text: lowercase and remove punctuation
        text = text.lower()
        text = text.translate(str.maketrans('', '', string.punctuation))
        return text.split()

    def get_sentence_vector(self, tokens):
        # Convert tokens to word vectors and pad sequences
        vector = torch.zeros(self.max_len, self.word_vectors.shape[1])
        for i, token in enumerate(tokens):
            if i >= self.max_len:
                break
            if token in self.vocab:
                vector[i] = torch.tensor(self.word_vectors[self.vocab[token]])
        return rnn_utils.pad_sequence([vector], batch_first=True).squeeze(0)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# Load pre-trained word embeddings
word_data = torch.load('skip-gram-word-vectors.pt', map_location=device)
word_vectors = word_data['vectors']
vocab = word_data['vocab']


# Load training and test data
train_data = pd.read_csv('train_data.csv').head(20000)
test_data = pd.read_csv('test_data.csv')


# Model hyperparameters
input_size = word_vectors.shape[1]
hidden_size = 128
output_size = 4
batch_size = 64
num_epochs = 20
learning_rate = 0.001
max_text_length = 100


# Create datasets and dataloaders
train_dataset = CustomTextDataset(train_data, word_vectors, vocab, max_text_length)
test_dataset = CustomTextDataset(test_data, word_vectors, vocab, max_text_length)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size)


# Initialize the LSTM text classifier model
model = LSTMTextClassifier(input_size, hidden_size, output_size).to(device)


# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)


# Training loop
for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    for inputs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}")


# Evaluation on test set
model.eval()
correct = 0
total = 0
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Accuracy on test set: {100 * correct / total}%")


# Save the trained model
torch.save(model.state_dict(), 'skip-gram-classification-model.pt')

from sklearn.metrics import precision_recall_fscore_support

model.eval()
correct = 0
total = 0
predicted_labels = []
true_labels = []
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        predicted_labels.extend(predicted.cpu().numpy())
        true_labels.extend(labels.cpu().numpy())

predicted_labels = np.array(predicted_labels)
true_labels = np.array(true_labels)


# Compute precision, recall, F1 score, and support
precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')


# Print evaluation metrics
print(f"Accuracy on test set: {100 * correct / total}%")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")

import torch
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap=cmap, xticklabels=classes, yticklabels=classes)
    plt.title(title)
    plt.xlabel('Predicted label')
    plt.ylabel('True label')
    plt.show()

# Evaluate on train set
model.eval()
train_true_labels = []
train_predicted_labels = []

with torch.no_grad():
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        train_true_labels.extend(labels.cpu().numpy())
        train_predicted_labels.extend(predicted.cpu().numpy())

train_confusion_matrix = confusion_matrix(train_true_labels, train_predicted_labels)
plot_confusion_matrix(train_confusion_matrix, classes=['Class 1', 'Class 2', 'Class 3', 'Class 4'], title='Train Confusion Matrix')

# Evaluate on test set
test_true_labels = []
test_predicted_labels = []

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        test_true_labels.extend(labels.cpu().numpy())
        test_predicted_labels.extend(predicted.cpu().numpy())

test_confusion_matrix = confusion_matrix(test_true_labels, test_predicted_labels)
plot_confusion_matrix(test_confusion_matrix, classes=['Class 1', 'Class 2', 'Class 3', 'Class 4'], title='Test Confusion Matrix')